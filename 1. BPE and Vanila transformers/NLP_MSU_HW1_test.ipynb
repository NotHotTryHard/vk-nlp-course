{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBA5IPyb4BFH"
      },
      "source": [
        "# Ğ•Ğ³Ğ¾ Ğ²ĞµĞ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾, \"Ğ´Ğ¾Ğ¼Ğ°ÑˆĞºĞ° â„–1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOnY6pwvpghE"
      },
      "source": [
        "Ğ’ ÑÑ‚Ğ¾Ğ¹ Ğ´Ğ¾Ğ¼Ğ°ÑˆĞ½ĞµĞ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ²Ğ°Ğ¼ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑÑ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ğ°Ñ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ Byte-level BPE Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ¸ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆÑƒÑ LM.  \n",
        "\n",
        "Ğ”Ğ¾Ğ¼Ğ°ÑˆĞ½ÑÑ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° ÑĞ¾ÑÑ‚Ğ¾Ğ¸Ñ‚ Ğ¸Ğ· Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ±Ğ»Ğ¾ĞºĞ¾Ğ²: Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ°, Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Transformer Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ Ñ Ñ€ÑƒÑÑĞºĞ¸Ğ¼Ğ¸ Ğ°Ğ½ĞµĞºĞ´Ğ¾Ñ‚Ğ°Ğ¼Ğ¸!\n",
        "\n",
        "ĞĞ±ÑƒÑ‡ĞµĞ½Ğ½Ñ‹Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ²Ñ‹Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ Ğ½Ğ° [ğŸ¤— HuggingFace](https://huggingface.co/). Ğ—Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞ¹Ñ‚ĞµÑÑŒ Ñ‚Ğ°Ğ¼, Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑˆĞ¸Ñ‚ĞµÑÑŒ Ğ½Ğ° [deep vk](https://huggingface.co/deepvk) Ğ¸ ÑĞ¾Ğ·Ğ´Ğ°Ğ¹Ñ‚Ğµ ÑĞµĞ±Ğµ API Ñ‚Ğ¾ĞºĞµĞ½.\n",
        "\n",
        "Ğ¡Ğ»ĞµĞ´ÑƒĞ¹Ñ‚Ğµ ÑÑ‡ĞµĞ¹ĞºĞ°Ğ¼ Ñ‚ĞµÑ‚Ñ€Ğ°Ğ´ĞºĞ¸ Ğ¸ Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ÑĞ¹Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ğµ ÑÑ‡ĞµĞ¹ĞºĞ¸. Ğ’ ĞºĞ¾Ğ½Ñ†Ğµ Ñ‚ĞµÑ‚Ñ€Ğ°Ğ´ĞºĞ¸ Ğ²Ñ‹ Ğ½Ğ°Ğ¹Ğ´ĞµÑ‚Ğµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ ÑĞ¾ Ğ·Ğ²ĞµĞ·Ğ´Ğ¾Ñ‡ĞºĞ¾Ğ¹, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ±Ğ°Ğ»Ğ»!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0byNYx5dzB4b",
        "outputId": "4f5ebf72-8cae-4856-dfc6-ae01271ddc62"
      },
      "outputs": [],
      "source": [
        "# Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ğ¼ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ¸Ğ±Ğ»Ğ¸Ğ¾Ñ‚ĞµĞºĞ¸\n",
        "\n",
        "#%pip install --quiet datasets livelossplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UILR1tu3z9oI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mike/anaconda3/envs/nlp2_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# ĞĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ğµ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹\n",
        "\n",
        "import inspect\n",
        "import json\n",
        "import os\n",
        "from collections import Counter\n",
        "from dataclasses import dataclass\n",
        "from functools import lru_cache, partial\n",
        "from pathlib import Path\n",
        "\n",
        "import regex as re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import HfApi, PyTorchModelHubMixin, interpreter_login, snapshot_download\n",
        "from huggingface_hub.utils import SoftTemporaryDirectory\n",
        "from livelossplot import PlotLosses\n",
        "from torch import Tensor\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.auto import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4p7OLSivnPW0"
      },
      "outputs": [],
      "source": [
        "# Ğ­Ñ‚Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸ĞµĞ¹ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¿Ğ¾Ğ¼ĞµÑ‡ĞµĞ½Ñ‹ Ğ²ÑĞµ Ğ¼ĞµÑÑ‚Ğ°, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ´Ğ¾Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ÑŒ\n",
        "# Ğ­Ñ‚Ğ¾ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ ĞºĞ°Ğº Ñ†ĞµĞ»Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸, Ñ‚Ğ°Ğº Ğ¸ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ‡Ğ°ÑÑ‚Ğ¸ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ Ğ½Ğ¸Ñ…\n",
        "# Ğ’ÑĞµĞ³Ğ´Ğ° Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ²Ğ¾ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ¸Ğ½Ñ‚Ñ€Ğ¾ÑĞ¿ĞµĞºÑ†Ğ¸ĞµĞ¹ Ğ¸ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ¼ĞµÑÑ‚Ğ° Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ ÑÑ‚Ğ¾Ğ¹ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ :)\n",
        "\n",
        "\n",
        "def todo():\n",
        "    stack = inspect.stack()\n",
        "    caller_frame = stack[1]\n",
        "    function_name = caller_frame.function\n",
        "    line_number = caller_frame.lineno\n",
        "    raise NotImplementedError(f\"TODO at {function_name}, line {line_number}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCkJJp2JK99x",
        "outputId": "3725be63-2cc3-471a-ad16-127334b85556"
      },
      "outputs": [],
      "source": [
        "interpreter_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVWKkwaryDTq",
        "outputId": "e15b8269-e8ce-4bac-bd3a-cb395c8f4761"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Homework repository: 'NotHotTryHard/llm-course-hw1'\n"
          ]
        }
      ],
      "source": [
        "# ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ±ÑƒĞ´ÑƒÑ‰ĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ°\n",
        "username = HfApi().whoami()[\"name\"]\n",
        "REPO_NAME = f\"{username}/llm-course-hw1\"  # Ğ˜Ğ»Ğ¸ ĞºĞ°Ğº Ğ²Ğ°Ğ¼ Ñ…Ğ¾Ñ‡ĞµÑ‚ÑÑ\n",
        "\n",
        "print(f\"Homework repository: '{REPO_NAME}'\")\n",
        "\n",
        "# Ğ˜ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğµ Ğ²ĞµÑ‰Ğ¸\n",
        "SEED = 0xC0FFEE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxN5JUbZ3ToV"
      },
      "source": [
        "# Ğ”Ğ°Ñ‚Ğ°ÑĞµÑ‚\n",
        "\n",
        "ĞŸĞµÑ€Ğ²Ñ‹Ğ¼ Ğ´ĞµĞ»Ğ¾Ğ¼ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ: [ğŸ¤— IgorVolochay/russian_jokes](https://huggingface.co/datasets/IgorVolochay/russian_jokes)\n",
        "\n",
        "Ğ˜ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼ Ğ½Ğ° Ğ½Ğ¸Ñ… ğŸ‘€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from datasets import load_dataset, load_from_disk\n",
        "\n",
        "dataset_dir = \"data\"\n",
        "\n",
        "if os.path.exists(dataset_dir):\n",
        "    dataset = load_from_disk(dataset_dir)\n",
        "else:\n",
        "    dataset = load_dataset(\"IgorVolochay/russian_jokes\", data_files=\"dataset.csv\")\n",
        "    dataset.save_to_disk(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "a7cfb7fe4e0e484784c16947848f296e",
            "23829bfc269042948448534c24709134",
            "c59603b6d2484a95b18f009a81d5bc66",
            "82a2000df7e543029f0964f399642d5d",
            "f4de1a432cd54914939b6b70e6af7dcc",
            "afb8e5c8b9ef4336bf6e2eee88d4e114",
            "ecd900fa3e114439822257ba77381f0a",
            "e6975b8856484e2f96d78fe4a23a8e10",
            "4bcfbe536a2d47a39d4293d998636243",
            "6cb7655e3cd541e5855462433aa534be",
            "74a8ce73ceb64b688147bb7a71d4c2c9",
            "494d0853e39641daa0805645ce6beb17",
            "34bf217aa66f4fb29d09f35f592c1bc9",
            "d49f51a25b964249852b50a2acc49634",
            "d6730505ea7d431fbfd80aa7a01dc790",
            "73a9344dc79e43f091c8d1b223cbcee4",
            "4e38bd08f29d40559bc7d339e03bd4c2",
            "8f3dde7227494dd9b0774ce28b388274",
            "0e3f8d3e5e5b4492a59f0d7d3186877e",
            "566df9d46f7943b7b672fe7dd9f7417c",
            "466b7df8811a413c95f08a580de6b89a",
            "75dbd3da373541b2bc952f7f6a164624",
            "e4231b41f41d421facafcdefb89969d7",
            "bd8e490fbdc5420f97d4c94f5e61b5c5",
            "4bc0fba67ddf478991c47aa6cab98ff4",
            "5d1434a6307d4ba9bed46f5d4ae730c0",
            "f470bf33537d462a883ef2d57df8bfbc",
            "25279ff26e0046899b173f33e3cea185",
            "24a0f86cb4504f6a88c4bcc9410a6882",
            "d6c63b0273ea460eb5e153e48101e332",
            "07238cfa6bd34bf0917a8622a1cd3b0d",
            "408079bc18cf4307b7a4aa0a81591979",
            "c541c5f56dd2474b84182f9703b4cda7"
          ]
        },
        "id": "rT78JNcqpRXW",
        "outputId": "72a24264-5b8c-4afe-ae65-c964a0b2fce2"
      },
      "outputs": [],
      "source": [
        "#dataset = load_dataset(\"IgorVolochay/russian_jokes\", data_files='dataset.csv')\n",
        "#print(\"\\n===\\n\".join(dataset[\"train\"][\"text\"][:3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7G7o6OdK99z",
        "outputId": "ddb5c277-107c-41f8-91cc-2eac3822bcd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 135497\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 15056\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¼ Ñ…Ğ¾Ğ»Ğ´Ğ°ÑƒÑ‚Ñ‹\n",
        "dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=SEED)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZzvdEVO3-kM"
      },
      "source": [
        "# Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ [6 Ğ±Ğ°Ğ»Ğ»Ğ¾Ğ²]\n",
        "\n",
        "Ğ’ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ° Ğ±ÑƒĞ´ĞµĞ¼ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ Byte-level BPE.\n",
        "\n",
        "Ğ”Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾:\n",
        "1. Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ ĞµĞ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ğ½Ğ°Ğ¼ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ Ğ¿Ğ¾ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ¸ Ğ½Ğ°Ğ±Ğ¾Ñ€ ÑĞ»Ğ¸ÑĞ½Ğ¸Ğ¹ Ğ¿Ğ¾ ÑÑ‚Ğ¾Ğ¼Ñƒ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ\n",
        "2. ĞĞ±ÑƒÑ‡Ğ¸Ğ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ½Ğ° Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ\n",
        "3. Ğ ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ°: ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¸ Ğ´ĞµĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "15U6H1iLU3kI"
      },
      "outputs": [],
      "source": [
        "# Ğ’ÑÑĞºĞ¸Ğµ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾ÑÑ‚Ğ¸\n",
        "\n",
        "WHITESPACE_SPLITTER = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
        "\n",
        "\n",
        "def bytes_to_unicode() -> dict[int, str]:\n",
        "    \"\"\"The original dictionary consists of 256 bytes and their corresponding Unicode characters.\n",
        "    For example, chr(33) is '!'. However, not all bytes have a visually appealing representation,\n",
        "    so such characters are skipped and replaced with the first available ones, i.e. shifted by 256.\n",
        "    \"\"\"\n",
        "    initial_bytes = (\n",
        "        list(range(ord(\"!\"), ord(\"~\") + 1)) +\n",
        "        list(range(ord(\"Â¡\"), ord(\"Â¬\") + 1)) +\n",
        "        list(range(ord(\"Â®\"), ord(\"Ã¿\") + 1)) +\n",
        "        list(range(ord(\"Ğ\"), ord(\"Ğ¯\") + 1)) +\n",
        "        list(range(ord(\"Ğ°\"), ord(\"Ñ\") + 1))\n",
        "    )\n",
        "    initial_chars = [chr(it) for it in initial_bytes]\n",
        "    n = 0\n",
        "    for byte in range(2**8):\n",
        "        if byte not in initial_bytes:\n",
        "            initial_bytes.append(byte)\n",
        "            initial_chars.append(chr(2**8 + n))\n",
        "            n += 1\n",
        "    return dict(sorted(zip(initial_bytes, initial_chars)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsckv3BhORZQ",
        "outputId": "a64efb81-b03b-4412-e0b6-465f82b866ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_values(['Ä€', 'Ä', 'Ä‚', 'Äƒ', 'Ä„', 'Ä…', 'Ä†', 'Ä‡', 'Äˆ', 'Ä‰', 'ÄŠ', 'Ä‹', 'ÄŒ', 'Ä', 'Ä', 'Ä', 'Ä', 'Ä‘', 'Ä’', 'Ä“', 'Ä”', 'Ä•', 'Ä–', 'Ä—', 'Ä˜', 'Ä™', 'Äš', 'Ä›', 'Äœ', 'Ä', 'Ä', 'ÄŸ', 'Ä ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', 'Ä¡', 'Ä¢', 'Ä£', 'Ä¤', 'Ä¥', 'Ä¦', 'Ä§', 'Ä¨', 'Ä©', 'Äª', 'Ä«', 'Ä¬', 'Ä­', 'Ä®', 'Ä¯', 'Ä°', 'Ä±', 'Ä²', 'Ä³', 'Ä´', 'Äµ', 'Ä¶', 'Ä·', 'Ä¸', 'Ä¹', 'Äº', 'Ä»', 'Ä¼', 'Ä½', 'Ä¾', 'Ä¿', 'Å€', 'Å', 'Å‚', 'Â¡', 'Â¢', 'Â£', 'Â¤', 'Â¥', 'Â¦', 'Â§', 'Â¨', 'Â©', 'Âª', 'Â«', 'Â¬', 'Åƒ', 'Â®', 'Â¯', 'Â°', 'Â±', 'Â²', 'Â³', 'Â´', 'Âµ', 'Â¶', 'Â·', 'Â¸', 'Â¹', 'Âº', 'Â»', 'Â¼', 'Â½', 'Â¾', 'Â¿', 'Ã€', 'Ã', 'Ã‚', 'Ãƒ', 'Ã„', 'Ã…', 'Ã†', 'Ã‡', 'Ãˆ', 'Ã‰', 'ÃŠ', 'Ã‹', 'ÃŒ', 'Ã', 'Ã', 'Ã', 'Ã', 'Ã‘', 'Ã’', 'Ã“', 'Ã”', 'Ã•', 'Ã–', 'Ã—', 'Ã˜', 'Ã™', 'Ãš', 'Ã›', 'Ãœ', 'Ã', 'Ã', 'ÃŸ', 'Ã ', 'Ã¡', 'Ã¢', 'Ã£', 'Ã¤', 'Ã¥', 'Ã¦', 'Ã§', 'Ã¨', 'Ã©', 'Ãª', 'Ã«', 'Ã¬', 'Ã­', 'Ã®', 'Ã¯', 'Ã°', 'Ã±', 'Ã²', 'Ã³', 'Ã´', 'Ãµ', 'Ã¶', 'Ã·', 'Ã¸', 'Ã¹', 'Ãº', 'Ã»', 'Ã¼', 'Ã½', 'Ã¾', 'Ã¿', 'Ğ', 'Ğ‘', 'Ğ’', 'Ğ“', 'Ğ”', 'Ğ•', 'Ğ–', 'Ğ—', 'Ğ˜', 'Ğ™', 'Ğš', 'Ğ›', 'Ğœ', 'Ğ', 'Ğ', 'ĞŸ', 'Ğ ', 'Ğ¡', 'Ğ¢', 'Ğ£', 'Ğ¤', 'Ğ¥', 'Ğ¦', 'Ğ§', 'Ğ¨', 'Ğ©', 'Ğª', 'Ğ«', 'Ğ¬', 'Ğ­', 'Ğ®', 'Ğ¯', 'Ğ°', 'Ğ±', 'Ğ²', 'Ğ³', 'Ğ´', 'Ğµ', 'Ğ¶', 'Ğ·', 'Ğ¸', 'Ğ¹', 'Ğº', 'Ğ»', 'Ğ¼', 'Ğ½', 'Ğ¾', 'Ğ¿', 'Ñ€', 'Ñ', 'Ñ‚', 'Ñƒ', 'Ñ„', 'Ñ…', 'Ñ†', 'Ñ‡', 'Ñˆ', 'Ñ‰', 'ÑŠ', 'Ñ‹', 'ÑŒ', 'Ñ', 'Ñ', 'Ñ'])\n"
          ]
        }
      ],
      "source": [
        "d = bytes_to_unicode()\n",
        "print(d.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yk919hENEFwL"
      },
      "outputs": [],
      "source": [
        "def merge(merge_pair: tuple[str, str], pair_frequences: Counter[tuple[str, str]], words_by_tokens: Counter[tuple[str]]):\n",
        "    \"\"\"Merges a given pair of tokens and update corresponding stats\n",
        "\n",
        "    Args:\n",
        "        merge_pair: The pair of tokens to be merged.\n",
        "        pair_frequences: A counter tracking the frequency of token pairs in the dataset.\n",
        "        words_by_tokens: A counter mapping tokenized words to their frequencies.\n",
        "\n",
        "    Returns:\n",
        "        Updated pair frequences and word tokenization w.r.t. to new token.\n",
        "    \"\"\"\n",
        "    new_words_by_tokens = Counter()\n",
        "\n",
        "    for word, freq in words_by_tokens.items():\n",
        "        new_word = []\n",
        "        i = 0\n",
        "        while i < len(word):\n",
        "            if i < len(word) - 1 and (word[i], word[i + 1]) == merge_pair:\n",
        "                new_word.append(word[i] + word[i + 1])\n",
        "                i += 2\n",
        "            else:\n",
        "                new_word.append(word[i])\n",
        "                i += 1\n",
        "        new_words_by_tokens[tuple(new_word)] += freq\n",
        "\n",
        "    new_pair_frequences = Counter()\n",
        "    for tokens, freq in new_words_by_tokens.items():\n",
        "        for i in range(len(tokens) - 1):\n",
        "            new_pair_frequences[(tokens[i], tokens[i+1])] += freq\n",
        "\n",
        "    return new_pair_frequences, new_words_by_tokens\n",
        "\n",
        "\n",
        "def train(data: list[str], vocab_size: int = 1024, special_tokens: list[str] = None):\n",
        "    \"\"\"Train BPE tokenizer on passed data\n",
        "\n",
        "    Args:\n",
        "        data: List of train documents\n",
        "        vocab_size: Size of target vocabulary\n",
        "        special_tokens: List of special tokens to add into vocabulary\n",
        "    Returns:\n",
        "        vocabulary: mapping from string token to id\n",
        "        merges: list of merges, each one is tuple of string tokens\n",
        "    \"\"\"\n",
        "    if vocab_size < 256:\n",
        "        raise ValueError(\"Vocab size can't be less than 256\")\n",
        "    if special_tokens is None:\n",
        "        special_tokens = []\n",
        "\n",
        "    # 1. Initialize vocabulary (using inverse one during training)\n",
        "    id2token = bytes_to_unicode()\n",
        "    merges = []\n",
        "\n",
        "    # 2. Load data\n",
        "    words_by_tokens = Counter()\n",
        "    for sample in tqdm(data, desc=\"Loading data\"):\n",
        "        # 2.1 Split into words\n",
        "        words = WHITESPACE_SPLITTER.findall(sample.strip())\n",
        "        for word in words:\n",
        "            # 2.2 Tokenize with base vocabulary\n",
        "            tokens = tuple(id2token[b] for b in word.encode('utf-8'))\n",
        "            words_by_tokens[tokens] += 1\n",
        "\n",
        "    # 3. Calculate statistic of token's pairs\n",
        "    pair_frequences = Counter()\n",
        "    for tokens, freq in words_by_tokens.items():\n",
        "        for i in range(len(tokens) - 1):\n",
        "            pair_frequences[(tokens[i], tokens[i+1])] += freq\n",
        "\n",
        "    # 4. Build vocabulary\n",
        "    pbar = trange(vocab_size, desc=\"Building vocabulary\", initial=len(id2token) + len(special_tokens))\n",
        "    while len(id2token) < vocab_size - len(special_tokens):\n",
        "        if len(pair_frequences) == 0:\n",
        "            print(\"Not enough data to fulfil vocabulary\")\n",
        "            break\n",
        "\n",
        "        # 4.1 Find the most frequent pair and create new token\n",
        "        top_pair = max(pair_frequences, key=pair_frequences.get)\n",
        "        new_token = top_pair[0] + top_pair[1]\n",
        "        del pair_frequences[top_pair]\n",
        "\n",
        "        # 4.2 Add to vocabulary\n",
        "        if new_token in id2token.values():\n",
        "            continue\n",
        "        id2token[len(id2token)] = new_token\n",
        "        merges.append(top_pair)\n",
        "\n",
        "        # 4.3 Update stats and merge the top pair in all tokens\n",
        "        pair_frequences, words_by_tokens = merge(top_pair, pair_frequences, words_by_tokens)\n",
        "\n",
        "        pbar.update()\n",
        "    pbar.close()\n",
        "\n",
        "    # 5. Add special tokens\n",
        "    for special_token in special_tokens:\n",
        "        id2token[len(id2token)] = special_token\n",
        "\n",
        "    return {v: k for k, v in id2token.items()}, merges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "a09b3fed74ed42efb5a3f71e5eae676c",
            "17262cca283248a98297387d6824d5bb",
            "51b3b59a23ad411988fc656d30d8fc8a",
            "1208ee3c939b4e18bcbf992a00bde69c",
            "4c1ebcad0d764e60a4948434d9993a2f",
            "ed5bfb7134314419a909b305e43d432b",
            "f0ae019189404e27a4286b05922c8f9e",
            "1a8fccc151714a19856de84a0416d3d8",
            "1e923b43f03f4bfe8c1315d8e98e049b",
            "513fd997a1444193bcaa161bb7c4e6b7",
            "963ec243a52f481d8e67977600e9b34d",
            "27d8bbba523844ce9568c9d8b6690cfa",
            "b4cf7e2c4a664fa398e6e60ae11e2348",
            "808c00da14224708918d15a5000434fc",
            "da58846238f54b6790acd3898da7b9a6",
            "880b38716d5f4eb5b4f7dfba3390dc45",
            "9fdad1a5749346b09daf54d983a22964",
            "9970c0d3b42b4ff08d31eeae1d0efe51",
            "86d07832c915484fa50db62c333922ec",
            "51fa888c7bf34a74a0742fc197d9487a",
            "7007abc4f18e4d7997aa1d7265c25eb4",
            "8142e932c2b94414bd27d4223c3a3d6c"
          ]
        },
        "id": "iLwur-KgK990",
        "outputId": "449b7f94-50ef-4a3c-eca6-620f8355d4c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 135497/135497 [00:06<00:00, 21014.34it/s]\n",
            "Building vocabulary:  28%|â–ˆâ–ˆâ–Š       | 289/1024 [01:13<26:09,  2.14s/it]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ½Ğ° Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ñ‚ĞµĞºÑÑ‚Ğ°Ñ…\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Ğ”Ğ»Ñ Ğ½Ğ°ÑˆĞµĞ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ñ…Ğ²Ğ°Ñ‚Ğ¸Ñ‚ Ğ¸ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ, Ğ½Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞµĞ³Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ!\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m vocab, merges \u001b[38;5;241m=\u001b[39m train(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m], vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, special_tokens\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[EOS]\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
            "Cell \u001b[0;32mIn[28], line 106\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data, vocab_size, special_tokens)\u001b[0m\n\u001b[1;32m    103\u001b[0m     merges\u001b[38;5;241m.\u001b[39mappend(top_pair)\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;66;03m# 4.3 Update stats and merge the top pair in all tokens\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     pair_frequences, words_by_tokens \u001b[38;5;241m=\u001b[39m merge(top_pair, pair_frequences, words_by_tokens)\n\u001b[1;32m    108\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m    109\u001b[0m pbar\u001b[38;5;241m.\u001b[39mclose()\n",
            "Cell \u001b[0;32mIn[28], line 33\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(merge_pair, pair_frequences, words_by_tokens)\u001b[0m\n\u001b[1;32m     31\u001b[0m new_pairs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(new_tokens) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     new_pairs\u001b[38;5;241m.\u001b[39mappend((new_tokens[j], new_tokens[j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m original_pairs:\n\u001b[1;32m     35\u001b[0m     pair_frequences[pair] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m count\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ĞĞ±ÑƒÑ‡Ğ°ĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ½Ğ° Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ñ‚ĞµĞºÑÑ‚Ğ°Ñ…\n",
        "# Ğ”Ğ»Ñ Ğ½Ğ°ÑˆĞµĞ¹ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ Ñ…Ğ²Ğ°Ñ‚Ğ¸Ñ‚ Ğ¸ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ°Ñ€Ñ, Ğ½Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞµĞ³Ğ¾ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ° Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ!\n",
        "\n",
        "\n",
        "vocab, merges = train(dataset[\"train\"][\"text\"], vocab_size=1024, special_tokens=[\"[EOS]\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcsapJUAK990",
        "outputId": "29a6ecf6-84a4-42d1-f085-a414417e5a9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token #512: 'Ñ‹Ğ²'\n",
            "Token #614: ' ÑĞ¼'\n",
            "Token #768: ' Ğ¿Ğ¾Ğ¼'\n",
            "Token #888: 'Ğ°Ñ‚ĞµĞ»ÑŒ'\n",
            "Token #1022: ' Ğ´ĞµĞ²ÑƒÑˆ'\n"
          ]
        }
      ],
      "source": [
        "# ĞŸĞ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼ Ğ½Ğ° ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹\n",
        "\n",
        "random_tokens = [512, 614, 768, 888, 1022]\n",
        "unicode_to_bytes = {v: k for k, v in bytes_to_unicode().items()}\n",
        "for token_id in random_tokens:\n",
        "    token = [k for k, v in vocab.items() if v == token_id][0]\n",
        "    raw_bytes = bytes([unicode_to_bytes[it] for it in token])\n",
        "    print(f\"Token #{token_id}: '{raw_bytes.decode('utf-8', errors='replace')}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugUz7cma1Czs"
      },
      "outputs": [],
      "source": [
        "class ByteLevelBPETokenizer:\n",
        "\n",
        "    def __init__(self, vocab: dict[str, int], merges: list[tuple[str, str]], eos_token: str = \"[EOS]\"):\n",
        "        \"\"\"Byte-Level BPE Tokenizer\n",
        "\n",
        "        Args:\n",
        "            vocab: mapping from string token to id\n",
        "            merges: list of merges in prioritized order\n",
        "            eos_token: string representation of EOS token\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        if eos_token not in vocab:\n",
        "            raise ValueError(\"There is no EOS token in vocab\")\n",
        "        self.byte_encoder = bytes_to_unicode()\n",
        "        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}\n",
        "        self.token2id = vocab\n",
        "        self.id2token = {v: k for k, v in self.token2id.items()}\n",
        "        self.eos_token = eos_token\n",
        "        self.eos_token_id = self.token2id[eos_token]\n",
        "\n",
        "        # The closer the pair is to the beginning, the higher the rank\n",
        "        self.merges = merges\n",
        "        self.bpe_ranks = {pair: i for i, pair in enumerate(merges)}\n",
        "\n",
        "    def get_pairs(self, word: tuple[str]) -> set[tuple[str, str]]:\n",
        "        pairs = set()\n",
        "        for i in range(len(word) - 1):\n",
        "            pairs.add((word[i], word[i+1]))\n",
        "        return pairs\n",
        "\n",
        "\n",
        "    @lru_cache\n",
        "    def bpe(self, word: tuple[str]) -> tuple[str]:\n",
        "        \"\"\"Process word into tokenized representation.\n",
        "        Word is a tuple of base tokens, i.e. bytes.\n",
        "\n",
        "        Under the hood:\n",
        "        1. Tracks the set of token pairs, bi-grams\n",
        "        2. While possible, replaces the highest-ranking pair with its union\n",
        "\n",
        "        Args:\n",
        "            word: list of base string tokens\n",
        "        Return:\n",
        "            list of BPE tokens\n",
        "        \"\"\"\n",
        "        if len(word) == 1:\n",
        "            return word\n",
        "\n",
        "        word = list(word)\n",
        "        pairs = self.get_pairs(tuple(word))\n",
        "\n",
        "        while True:\n",
        "            candidate = None\n",
        "            min_rank = float('inf')\n",
        "            for pair in pairs:\n",
        "                if pair in self.bpe_ranks and self.bpe_ranks[pair] < min_rank:\n",
        "                    min_rank = self.bpe_ranks[pair]\n",
        "                    candidate = pair\n",
        "\n",
        "            if candidate is None:\n",
        "                break\n",
        "\n",
        "            first, second = candidate\n",
        "            new_word = []\n",
        "            i = 0\n",
        "            while i < len(word):\n",
        "                try:\n",
        "                    j = word.index(first, i)\n",
        "                except ValueError:\n",
        "                    new_word.extend(word[i:])\n",
        "                    break\n",
        "\n",
        "                new_word.extend(word[i:j])\n",
        "                if j < len(word) - 1 and word[j] == first and word[j+1] == second:\n",
        "                    new_word.append(first + second)\n",
        "                    i = j + 2\n",
        "                else:\n",
        "                    new_word.append(word[j])\n",
        "                    i = j + 1\n",
        "\n",
        "            word = new_word\n",
        "            if len(word) == 1:\n",
        "                break\n",
        "            else:\n",
        "                pairs = self.get_pairs(tuple(word))\n",
        "        return tuple(word)\n",
        "\n",
        "    def encode(self, text: str, add_eos_token: bool = True) -> list[int]:\n",
        "        \"\"\"Convert string to list of token ids.\n",
        "\n",
        "        Args:\n",
        "            text: input string, may contain multiple words\n",
        "            add_eos_token: whether to add eos token id at the end\n",
        "        Return:\n",
        "            list of ints, ids of tokenized text\n",
        "        \"\"\"\n",
        "        words = WHITESPACE_SPLITTER.findall(text)\n",
        "        token_ids = []\n",
        "        for word in words:\n",
        "            word_bytes = word.encode('utf-8')\n",
        "            base_tokens = tuple(self.byte_encoder[b] for b in word_bytes)\n",
        "            bpe_tokens = self.bpe(base_tokens)\n",
        "            for token in bpe_tokens:\n",
        "                if token in self.token2id:\n",
        "                    token_ids.append(self.token2id[token])\n",
        "                else:\n",
        "                    for char in token:\n",
        "                        token_ids.append(self.token2id.get(char, -1))\n",
        "        if add_eos_token:\n",
        "            token_ids.append(self.eos_token_id)\n",
        "        return token_ids\n",
        "\n",
        "\n",
        "    def decode(self, idx: list[int]) -> str:\n",
        "        \"\"\"Convert list of tokens' ids to text, opposite to encode method\n",
        "\n",
        "        Args:\n",
        "            idx: list of tokens' ids\n",
        "        Return:\n",
        "            string, decoded text\n",
        "        \"\"\"\n",
        "        tokens = [self.id2token[i] for i in idx if i in self.id2token and self.id2token[i] != self.eos_token]\n",
        "        byte_list = []\n",
        "        for token in tokens:\n",
        "            for ch in token:\n",
        "                byte_list.append(self.byte_decoder.get(ch, ord('?')))\n",
        "        byte_string = bytes(byte_list)\n",
        "        return byte_string.decode('utf-8', errors='replace')\n",
        "\n",
        "    def push_to_hub(self, repo_id, *, private=None, token=None):\n",
        "        api = HfApi()\n",
        "        repo_id = api.create_repo(repo_id=repo_id, token=token, private=private, exist_ok=True).repo_id\n",
        "\n",
        "        # Push the files to the repo in a single commit\n",
        "        with SoftTemporaryDirectory() as tmp:\n",
        "            save_directory = Path(tmp) / repo_id\n",
        "            save_directory.mkdir(parents=True)\n",
        "            with open(save_directory / \"vocabulary.json\", \"w\") as f_out:\n",
        "                print(json.dumps(self.token2id, indent=2), file=f_out)\n",
        "            with open(save_directory / \"merges.json\", \"w\") as f_out:\n",
        "                print(json.dumps({\"merges\": self.merges}), file=f_out)\n",
        "\n",
        "            return api.upload_folder(repo_id=repo_id, folder_path=save_directory, token=token)\n",
        "\n",
        "    @classmethod\n",
        "    def from_pretrained(cls, pretrained_model_name_or_path, *, token=None, **model_kwargs):\n",
        "        if not os.path.isdir(pretrained_model_name_or_path):\n",
        "            storage_folder = snapshot_download(repo_id=pretrained_model_name_or_path, token=token)\n",
        "        else:\n",
        "            storage_folder = pretrained_model_name_or_path\n",
        "        storage_folder = Path(storage_folder)\n",
        "        with open(storage_folder / \"vocabulary.json\", \"r\") as f_in:\n",
        "            vocab = json.load(f_in)\n",
        "        with open(storage_folder / \"merges.json\", \"r\") as f_in:\n",
        "            merges = [tuple(it) for it in json.load(f_in)[\"merges\"]]\n",
        "        return cls(vocab, merges, **model_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xRTQzO3wK991"
      },
      "outputs": [],
      "source": [
        "# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€\n",
        "\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(vocab, merges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "-9m_65vBK991",
        "outputId": "d30bc90d-e842-4438-95a6-968f4e16b93a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/NotHotTryHard/llm-course-hw1/commit/edf11ccfc2c4d9fddf6d1e687808406f50a50864', commit_message='Upload folder using huggingface_hub', commit_description='', oid='edf11ccfc2c4d9fddf6d1e687808406f50a50864', pr_url=None, repo_url=RepoUrl('https://huggingface.co/NotHotTryHard/llm-course-hw1', endpoint='https://huggingface.co', repo_type='model', repo_id='NotHotTryHard/llm-course-hw1'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ½Ğ° Ñ…Ğ°Ğ±\n",
        "\n",
        "tokenizer.push_to_hub(REPO_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ce6945736f7c4c839190e0404f370a1a",
            "91e13de6ce154bb09173c4f9f333611b",
            "f81001a64a784ae7a8d09fe258376e1d",
            "ffa04c096fc0464db8182467a307a2ae",
            "b976e96a647b4f40a50965b3cef1c8a5",
            "a4f01f1d458a453d8241de282a374b19",
            "b26a32b517324844b77e3de793b6c47d",
            "013f1b28161c4b2888981b2279309a08",
            "b9b9619cfb0f4451985c6466b0486fb9",
            "4b35e808896a4a37aab51a068f242c43",
            "b08ba319d12f4d15bd7ec8bea32a90f4"
          ]
        },
        "id": "S9VohtKrK991",
        "outputId": "c00aeffa-b063-4721-c948-8b4ad4c882f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 7 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 33325.91it/s]\n"
          ]
        }
      ],
      "source": [
        "# Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ñ Ñ…Ğ°Ğ±Ğ°\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer.from_pretrained(REPO_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFvf_Q8knPW4",
        "outputId": "76bb98fb-e441-43c4-cb1c-a873c00f8153"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[859, 346, 819, 545, 414, 369, 322, 340, 401, 422, 63, 421, 366, 426, 321, 394, 681, 833, 483, 698, 722, 846, 470, 44, 545, 414, 369, 322, 340, 401, 422, 462, 425, 403, 400, 929, 341, 387, 380, 402, 336, 444, 409, 380, 436, 567, 413, 343, 414, 455, 328, 323, 46, 1023]\n",
            "Ğ§|Ñ‚Ğ¾| Ğ±Ñ‹Ğ»Ğ¾| Ğ¿Ğ¾Ğ»|Ğ³|Ğ¾Ğ´|Ğ°| Ğ½|Ğ°Ğ·|Ğ°Ğ´|?| ĞŸ|Ğ¾Ğ¼|Ğ¸Ğ¼|Ğ¾| Ğ³|Ñ€Ğ°Ğ½|Ğ´Ğ¸|Ğ¾Ğ·|Ğ½Ñ‹Ñ…| ÑĞ¾Ğ±|Ñ‹Ñ‚|Ğ¸Ğ¹|,| Ğ¿Ğ¾Ğ»|Ğ³|Ğ¾Ğ´|Ğ°| Ğ½|Ğ°Ğ·|Ğ°Ğ´| Ğ±Ñ‹|Ğ»Ğ¸| Ğµ|Ñ‰|Ñ‘| Ñ|ĞµĞ¼|Ğ¸Ğ½|Ğ°Ñ€|Ñ‹| Ğ¿Ğ¾| Ğ»|Ğ¸Ğ½|ĞµĞ¹|Ğ½Ğ¾Ğ¹| Ğ°|Ğ»|Ğ³|ĞµĞ±|Ñ€|Ğµ|.|\n",
            "Ğ§Ñ‚Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ¿Ğ¾Ğ»Ğ³Ğ¾Ğ´Ğ° Ğ½Ğ°Ğ·Ğ°Ğ´? ĞŸĞ¾Ğ¼Ğ¸Ğ¼Ğ¾ Ğ³Ñ€Ğ°Ğ½Ğ´Ğ¸Ğ¾Ğ·Ğ½Ñ‹Ñ… ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹, Ğ¿Ğ¾Ğ»Ğ³Ğ¾Ğ´Ğ° Ğ½Ğ°Ğ·Ğ°Ğ´ Ğ±Ñ‹Ğ»Ğ¸ ĞµÑ‰Ñ‘ ÑĞµĞ¼Ğ¸Ğ½Ğ°Ñ€Ñ‹ Ğ¿Ğ¾ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ Ğ°Ğ»Ğ³ĞµĞ±Ñ€Ğµ.\n"
          ]
        }
      ],
      "source": [
        "# Ğ¡Ğ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼ Ğ½Ğ° Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñƒ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ°\n",
        "\n",
        "text = \"Ğ§Ñ‚Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ¿Ğ¾Ğ»Ğ³Ğ¾Ğ´Ğ° Ğ½Ğ°Ğ·Ğ°Ğ´? ĞŸĞ¾Ğ¼Ğ¸Ğ¼Ğ¾ Ğ³Ñ€Ğ°Ğ½Ğ´Ğ¸Ğ¾Ğ·Ğ½Ñ‹Ñ… ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹, Ğ¿Ğ¾Ğ»Ğ³Ğ¾Ğ´Ğ° Ğ½Ğ°Ğ·Ğ°Ğ´ Ğ±Ñ‹Ğ»Ğ¸ ĞµÑ‰Ñ‘ ÑĞµĞ¼Ğ¸Ğ½Ğ°Ñ€Ñ‹ Ğ¿Ğ¾ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğ¹ Ğ°Ğ»Ğ³ĞµĞ±Ñ€Ğµ.\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)\n",
        "reverse_text = [tokenizer.decode([it]) for it in ids]\n",
        "print(\"|\".join(reverse_text))\n",
        "print(tokenizer.decode(ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "e5087d27c4f14a28bfb73740fa147d3a",
            "ef5bee8e8d2f4d8c91ba14e77dda8d01",
            "be6ceb6f27af40aba535c445806e297b",
            "f2a0e82016804d2ca04aeb19c0d936e5",
            "564c90bbde8442f59aa264ace4f8a90b",
            "1f3b2354ef974753bf0057ff07cdd208",
            "468d88309904488a817e7b81a392c8b3",
            "75ddc70c138c42389c14a293a68aade2",
            "946f2a1b3aa34be2a278e291fdb530e8",
            "f94a9f0d86294b0288ad87412ec2ca5d",
            "69fa3278c9ff402784c86c44d74e3e70"
          ]
        },
        "id": "_QgpwFYiK991",
        "outputId": "3a0efb91-2cff-4fc6-b029-adeda727f4fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15056/15056 [00:20<00:00, 720.37it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average token len per sample: 74.61\n",
            "Minimum and maximum lens are: 6 and 3474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ĞŸĞ¾ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸ Ğ¿Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸, Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ğ¼ÑÑ Ñ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€Ğ¾Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ñƒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
        "\n",
        "lens = []\n",
        "for text in tqdm(dataset[\"test\"][\"text\"]):\n",
        "    ids = tokenizer.encode(text)\n",
        "    lens.append(len(ids))\n",
        "\n",
        "print(f\"Average token len per sample: {sum(lens) / len(lens):.2f}\")\n",
        "print(f\"Minimum and maximum lens are: {min(lens)} and {max(lens)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwN3mfmznPW5"
      },
      "source": [
        "Ğ”Ğ¾Ğ»Ğ¶Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ² ÑÑ€ĞµĞ´Ğ½ĞµĞ¼ Ğ¿Ğ¾ 70 Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ½Ğ° Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ.\n",
        "ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ² 128 Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ±ÑƒĞ´ĞµÑ‚ Ğ²Ğ¿Ğ¾Ğ»Ğ½Ğµ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub1FljGXC7I-"
      },
      "source": [
        "# ĞœĞ¾Ğ´ĞµĞ»ÑŒ [10 Ğ±Ğ°Ğ»Ğ»Ğ¾Ğ²]\n",
        "\n",
        "Ğ’ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ñ‚Ñ€Ğ°Ğ½ÑÑ„Ğ¾Ñ€Ğ¼ĞµÑ€, Ğ² ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¼\n",
        "1. Ğ’ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ñ… ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ² Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ ALiBi\n",
        "2. ĞœĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ GQA\n",
        "3. Ğ’ Feed-Forward Ğ±Ğ»Ğ¾ĞºĞµ SwiGLU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ipZrCvkmK992"
      },
      "outputs": [],
      "source": [
        "# Ğ”Ğ»Ñ ÑƒĞ´Ğ¾Ğ±ÑÑ‚Ğ²Ğ° Ğ·Ğ°Ğ²ĞµĞ´ĞµĞ¼ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TransformerConfig:\n",
        "    n_layer: int\n",
        "    n_head: int\n",
        "    n_kv_head: int\n",
        "    hidden_dim: int\n",
        "    intermediate_dim: int\n",
        "    dropout: float = 0.1\n",
        "    vocab_size: int = 1024\n",
        "    max_seq_len: int = 128\n",
        "\n",
        "\n",
        "model_configs = {\n",
        "    \"nano\": TransformerConfig(n_layer=3, n_head=4, n_kv_head=2, hidden_dim=96, intermediate_dim=256),\n",
        "    \"mini\": TransformerConfig(n_layer=6, n_head=6, n_kv_head=3, hidden_dim=384, intermediate_dim=1024),\n",
        "    \"small\": TransformerConfig(n_layer=12, n_head=12, n_kv_head=6, hidden_dim=768, intermediate_dim=2048),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aYXMb5PEDFkt"
      },
      "outputs": [],
      "source": [
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, dim: int, eps: float = 1e-6):\n",
        "        \"\"\"Root Mean Square Layer Normalization\n",
        "\n",
        "        Args:\n",
        "            dim: Feature dimension\n",
        "            eps: Small constant for numerical stability\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.scale = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        rms = torch.sqrt((x ** 2).mean(-1, keepdim=True) + self.eps)\n",
        "        return self.scale * x / rms\n",
        "\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        \"\"\"Causal Self-Attention with support of\n",
        "        Grouped-Query Attention and ALiBi for positional encoding\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        assert self.config.hidden_dim % self.config.n_head == 0 \n",
        "        assert self.config.n_head % self.config.n_kv_head == 0\n",
        "        self.head_dim = self.config.hidden_dim // self.config.n_head\n",
        "        self.scale = self.head_dim**-0.5\n",
        "        self.q_per_kv = self.config.n_head // self.config.n_kv_head\n",
        "\n",
        "        # Init projection layers\n",
        "        self.q_proj = nn.Linear(self.config.hidden_dim, self.config.hidden_dim)\n",
        "        self.kv_proj = nn.Linear(self.config.hidden_dim, self.config.n_kv_head * 2 * self.head_dim)\n",
        "        self.out_proj = nn.Linear(self.config.hidden_dim, self.config.hidden_dim)\n",
        "\n",
        "        self.attn_dropout = nn.Dropout(self.config.dropout)\n",
        "\n",
        "        self.register_buffer(\"causal_mask\", self._create_causal_mask(self.config.max_seq_len))\n",
        "        self.register_buffer(\"alibi\", self._build_alibi_bias(self.config.n_head))\n",
        "\n",
        "    def _build_alibi_bias(self, num_heads: int) -> Tensor:\n",
        "        \"\"\"Build ALiBi for specified number of heads:\n",
        "\n",
        "        Returns:\n",
        "            Tensor with ALiBi biases, shape: [1, num heads, 1, 1]\n",
        "        \"\"\"\n",
        "        slopes = torch.pow(2, -torch.arange(0, num_heads, dtype=torch.float32) / num_heads)\n",
        "        return slopes.view(1, num_heads, 1, 1)\n",
        "    \n",
        "    def _create_causal_mask(self, max_seq_len: int) -> Tensor:\n",
        "        \"\"\"Create causal mask with ones where tokens can attend to each other.\n",
        "\n",
        "        Returns:\n",
        "            Tensor with causal mask, shape: [1, 1, seq len, seq len]\n",
        "        \"\"\"\n",
        "        tri_mask = torch.tril(torch.ones((max_seq_len, max_seq_len), dtype=torch.bool))\n",
        "        return tri_mask.view(1, 1, max_seq_len, max_seq_len)\n",
        "\n",
        "    def forward(self, x: Tensor, attention_mask: Tensor = None) -> Tensor:\n",
        "        \"\"\"Apply Self-Attention to input data with respect to pad tokens.\n",
        "\n",
        "        Args:\n",
        "            x: input tensor, shape [bs, seq len, hidden dim]\n",
        "            attention_mask: mask with zeros for pad tokens, shape [bs, seq len, hidden dim]\n",
        "        Returns:\n",
        "            result tensor, shape [bs, seq len, hidden dim]\n",
        "        \"\"\"\n",
        "        bs, seq_len, hidden_dim = x.size()\n",
        "\n",
        "        q = self.q_proj(x)\n",
        "        kv = self.kv_proj(x)\n",
        "        k, v = kv.chunk(2, dim=-1) \n",
        "\n",
        "        # Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸Ñ…\n",
        "        q = q.view(bs, seq_len, self.config.n_head, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(bs, seq_len, self.config.n_kv_head, self.head_dim)\n",
        "        v = v.view(bs, seq_len, self.config.n_kv_head, self.head_dim)\n",
        "        k = k.repeat_interleave(self.q_per_kv, dim=2).transpose(1, 2)\n",
        "        v = v.repeat_interleave(self.q_per_kv, dim=2).transpose(1, 2)\n",
        "\n",
        "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
        "\n",
        "        # Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ¼ Ğ¿Ğ¾Ğ·Ğ¸ÑˆĞ½Ğ°Ğ» ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¸\n",
        "        pos = torch.arange(seq_len, device=x.device)\n",
        "        rel_pos = pos.view(1, -1) - pos.view(-1, 1)\n",
        "        alibi_bias = -self.alibi * rel_pos.unsqueeze(0).unsqueeze(0).float()\n",
        "        attn_scores = attn_scores + alibi_bias\n",
        "\n",
        "        causal_mask = self.causal_mask[:, :, :seq_len, :seq_len]\n",
        "        attn_scores = attn_scores.masked_fill(~causal_mask, float('-inf'))\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(attention_mask.unsqueeze(1).unsqueeze(2) == 0, float('-inf'))\n",
        "\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "        attn_probs = self.attn_dropout(attn_probs)\n",
        "\n",
        "        context = torch.matmul(attn_probs, v)\n",
        "        context = context.transpose(1, 2).contiguous().view(bs, seq_len, self.config.hidden_dim)\n",
        "\n",
        "        output = self.out_proj(context)\n",
        "        return output\n",
        "\n",
        "\n",
        "class SwiGLU(nn.Module):\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        \"\"\"Gated Liner Unit with Swish Activation\"\"\"\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        # Init up- and down- projection layers\n",
        "        self.fc1 = nn.Linear(config.hidden_dim, config.intermediate_dim * 2)\n",
        "        self.fc2 = nn.Linear(config.intermediate_dim, config.hidden_dim)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"Apply SwiGLU to input data.\n",
        "\n",
        "        Args:\n",
        "            x: input tensor, shape [bs, seq len, hidden dim]\n",
        "        Returns:\n",
        "            result tensor, shape [bs, seq len, hidden dim]\n",
        "        \"\"\"\n",
        "        x_proj = self.fc1(x)\n",
        "        x1, x2 = x_proj.chunk(2, dim=-1)  # Ñ€Ğ°Ğ·Ğ´ĞµĞ»ÑĞµĞ¼\n",
        "        x2 = x2 * torch.sigmoid(x2) # swish: x2 * sigmoid(x2)\n",
        "        gated = x1 * x2\n",
        "        return self.fc2(gated)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        \"\"\"Base Transformer Block\n",
        "        - Causal Self-Attention and SwiGLU as main elements\n",
        "        - Pre-normalization via RMSNorm\n",
        "        - Regularization with dropouts before residuals\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.ln_1 = RMSNorm(config.hidden_dim)\n",
        "        self.res_dropout_1 = nn.Dropout(config.dropout)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "\n",
        "        self.ln_2 = RMSNorm(config.hidden_dim)\n",
        "        self.res_dropout_2 = nn.Dropout(config.dropout)\n",
        "        self.mlp = SwiGLU(config)\n",
        "\n",
        "    def forward(self, x: Tensor, attention_mask: Tensor = None) -> Tensor:\n",
        "        \"\"\"Apply Transformer Block to input data.\n",
        "\n",
        "        Args:\n",
        "            x: input tensor, shape [bs, seq len, hidden dim]\n",
        "            attention_mask: mask with zeros for pad tokens, shape [bs, seq len, hidden dim]\n",
        "        Returns:\n",
        "            result tensor, shape [bs, seq len, hidden dim]\n",
        "        \"\"\"\n",
        "        x_attn = self.attn(self.ln_1(x), attention_mask)\n",
        "        x = x + self.res_dropout_1(x_attn)\n",
        "\n",
        "        x_ff = self.mlp(self.ln_2(x))\n",
        "        x = x + self.res_dropout_2(x_ff)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TransformerForCausalLM(nn.Module, PyTorchModelHubMixin):\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        \"\"\"Transformer model for Language Modeling\"\"\"\n",
        "        super().__init__()\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.max_seq_len = config.max_seq_len\n",
        "        self.n_layer = config.n_layer\n",
        "        self.n_head = config.n_head\n",
        "        self.hidden_dim = config.hidden_dim\n",
        "        self.dropout = config.dropout\n",
        "\n",
        "        self.token_emb = nn.Embedding(self.vocab_size, self.hidden_dim)\n",
        "        self.emb_dropout = nn.Dropout(config.dropout)\n",
        "        self.layers = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n",
        "        self.ln_final = RMSNorm(config.hidden_dim)\n",
        "        self.lm_head = nn.Linear(self.hidden_dim, self.vocab_size, bias=False)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        print(f\"Number of parameters: {n_params / 1e6:.2f}M\")\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "        elif isinstance(module, RMSNorm):\n",
        "            torch.nn.init.ones_(module.scale)\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor = None) -> Tensor:\n",
        "        \"\"\"Calculate logits for given input ids.\n",
        "\n",
        "        Args:\n",
        "            x: input tensor, shape [bs, seq len, hidden dim]\n",
        "            attention_mask: mask with zeros for pad tokens, shape [bs, seq len, hidden dim]\n",
        "        Returns:\n",
        "            logits, shape [bs, seq len, hidden dim]\n",
        "        \"\"\"\n",
        "        x = self.token_emb(input_ids)\n",
        "        x = self.emb_dropout(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, attention_mask)\n",
        "        x = self.ln_final(x)\n",
        "        logits = self.lm_head(x)\n",
        "        return logits\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def generate(\n",
        "        self, idx: Tensor, max_new_tokens, eos_token_id, temperature=1.0, do_sample=False, top_k=None\n",
        "    ) -> Tensor:\n",
        "        \"\"\"Take a conditioning sequence of indices and complete the sequence max_new_tokens times,\n",
        "        feeding the predictions back into the model each time.\n",
        "\n",
        "        Args:\n",
        "            idx: tensor with conditional tokens, shape [seq len]\n",
        "            max_new_tokens: maximum number of new tokens\n",
        "            eos_token_id: index of EOS token to stop generation\n",
        "            temperature, do_sample, top_k: generation parameters\n",
        "        Return:\n",
        "            tensor with generated indexes\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx if idx.shape[1] <= self.max_seq_len else idx[:, -self.max_seq_len :]\n",
        "            logits = self(idx_cond)\n",
        "\n",
        "            # 1. Pluck the logits at the final step and scale by desired temperature\n",
        "            logits = logits[:, -1, :]  # [bs, vocab_size]\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # 2. Optionally crop the logits to only the top k options\n",
        "            if top_k is not None:\n",
        "                kth_value = torch.topk(logits, top_k, dim=-1)[0][..., -1, None]\n",
        "                mask = logits < kth_value\n",
        "                logits[mask] = float(\"-inf\")\n",
        "\n",
        "            # 3. apply softmax to convert logits to probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "            # 4. Either sample from the distribution or take the most likely element\n",
        "            if do_sample:\n",
        "                idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            else:\n",
        "                idx_next = torch.argmax(probs, dim=-1, keepdim=True)\n",
        "\n",
        "            # 5. Append sampled index to the running sequence and continue\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "            if idx_next == eos_token_id:\n",
        "                break\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ĞœĞ¾Ñ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚ĞºĞ° Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ RoPE Ğ¸ MHLA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MHLASelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        \"\"\"Self-Attention with support of\n",
        "            Multi-Headed Linear Attention and RoPE for positional encoding\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        assert self.config.hidden_dim % self.config.n_head == 0 \n",
        "        assert self.config.n_head % self.config.n_kv_head == 0\n",
        "        self.head_dim = self.config.hidden_dim // self.config.n_head\n",
        "        self.q_per_kv = self.config.n_head // self.config.n_kv_head\n",
        "\n",
        "        self.q_proj = nn.Linear(self.config.hidden_dim, self.config.hidden_dim)\n",
        "        self.kv_proj = nn.Linear(self.config.hidden_dim, self.config.n_kv_head * 2 * self.head_dim)\n",
        "        self.out_proj = nn.Linear(self.config.hidden_dim, self.config.hidden_dim)\n",
        "\n",
        "        self.attn_dropout = nn.Dropout(self.config.dropout)\n",
        "\n",
        "        # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ±ÑƒÑ„ĞµÑ€Ğ¾Ğ² Ğ´Ğ»Ñ RoPE\n",
        "        max_seq_len = self.config.max_seq_len\n",
        "        d = self.head_dim\n",
        "        \n",
        "        assert d % 2 == 0, \"head_dim Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ñ‡ĞµÑ‚Ğ½Ñ‹Ğ¼ Ğ´Ğ»Ñ RoPE\"\n",
        "        inv_freq = 1.0 / (10000 ** (torch.arange(0, d, 2, dtype=torch.float32) / d))\n",
        "        positions = torch.arange(max_seq_len, dtype=torch.float32)\n",
        "        sinusoid_inp = torch.einsum(\"i,j->ij\", positions, inv_freq)\n",
        "        cos = torch.cos(sinusoid_inp)\n",
        "        sin = torch.sin(sinusoid_inp)\n",
        "        # ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ¼ Ğ±ÑƒÑ„ĞµÑ€Ñ‹ Ñ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ·Ğ¼ĞµÑ€ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ğ´Ğ»Ñ ÑƒĞ´Ğ¾Ğ±ÑÑ‚Ğ²Ğ° Ğ¿Ñ€Ğ¸Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ:\n",
        "        self.register_buffer(\"rope_cos\", cos.unsqueeze(1))\n",
        "        self.register_buffer(\"rope_sin\", sin.unsqueeze(1))\n",
        "\n",
        "    def apply_rope(self, x: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ Rotary Positional Embedding Ğº Ñ‚ĞµĞ½Ğ·Ğ¾Ñ€Ñƒ x.\n",
        "            x:        [B, n_head, seq_len, head_dim]\n",
        "            cos, sin: [1, 1, seq_len, head_dim/2]\n",
        "        \"\"\"\n",
        "        x1 = x[..., ::2]\n",
        "        x2 = x[..., 1::2]\n",
        "        # [x1*cos - x2*sin, x1*sin + x2*cos]\n",
        "        x_rotated = torch.cat([x1 * cos - x2 * sin, x1 * sin + x2 * cos], dim=-1)\n",
        "        return x_rotated\n",
        "\n",
        "    def forward(self, x: torch.Tensor, attention_mask: torch.Tensor = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "            x: [batch_size, seq_len, hidden_dim]\n",
        "            attention_mask Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ, Ñ‚Ğ°Ğº ĞºĞ°Ğº ĞºĞ°ÑƒĞ·Ğ°Ğ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ñ‡ĞµÑ€ĞµĞ· Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ğµ.\n",
        "        \"\"\"\n",
        "        bs, seq_len, _ = x.size()\n",
        "\n",
        "        q = self.q_proj(x)\n",
        "        kv = self.kv_proj(x)\n",
        "        k, v = kv.chunk(2, dim=-1)\n",
        "\n",
        "        q = q.view(bs, seq_len, self.config.n_head, self.head_dim).transpose(1, 2)\n",
        "        k = k.view(bs, seq_len, self.config.n_kv_head, self.head_dim)\n",
        "        v = v.view(bs, seq_len, self.config.n_kv_head, self.head_dim)\n",
        "\n",
        "        k = k.repeat_interleave(self.q_per_kv, dim=2).transpose(1, 2)\n",
        "        v = v.repeat_interleave(self.q_per_kv, dim=2).transpose(1, 2) \n",
        "\n",
        "        cos = self.rope_cos[:seq_len].unsqueeze(0).transpose(1, 2)\n",
        "        sin = self.rope_sin[:seq_len].unsqueeze(0).transpose(1, 2)\n",
        "        q = self.apply_rope(q, cos, sin)\n",
        "        k = self.apply_rope(k, cos, sin)\n",
        "\n",
        "        # Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ phi: phi(x) = elu(x) + 1\n",
        "        phi_q = F.elu(q) + 1\n",
        "        phi_k = F.elu(k) + 1\n",
        "\n",
        "        # Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ MHLA Ñ‡ĞµÑ€ĞµĞ· ĞºĞ°ÑƒĞ·Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾Ğµ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ\n",
        "        outputs = []\n",
        "        S = None  # Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ğµ outer-Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ°\n",
        "        Z = None  # Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ğµ phi(k)\n",
        "        eps = 1e-6\n",
        "\n",
        "        for i in range(seq_len):\n",
        "            phi_k_i = phi_k[:, :, i, :]\n",
        "            v_i = v[:, :, i, :]\n",
        "            # Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ outer-Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ ÑˆĞ°Ğ³Ğ°\n",
        "            outer = torch.einsum(\"bnd,bne->bnde\", phi_k_i, v_i)\n",
        "            if i == 0:\n",
        "                S = outer\n",
        "                Z = phi_k_i\n",
        "            else:\n",
        "                S = S + outer\n",
        "                Z = Z + phi_k_i\n",
        "\n",
        "            phi_q_i = phi_q[:, :, i, :]\n",
        "            numerator = torch.einsum(\"bnd,bnde->bne\", phi_q_i, S)\n",
        "            denominator = torch.sum(phi_q_i * Z, dim=-1, keepdim=True)\n",
        "            output_i = numerator / (denominator + eps)\n",
        "            outputs.append(output_i)\n",
        "            \n",
        "        # cĞ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ Ğ²ÑĞµ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸, Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ğ½Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¸ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ğ³Ğ¾Ğ»Ğ¾Ğ²Ñ‹\n",
        "        out = torch.stack(outputs, dim=2)\n",
        "        out = self.attn_dropout(out)\n",
        "        out = out.transpose(1, 2).contiguous().view(bs, seq_len, self.config.hidden_dim)\n",
        "        output = self.out_proj(out)\n",
        "        return output\n",
        "    \n",
        "    \n",
        "class ModifiedBlock(nn.Module):\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        \"\"\"Base Transformer Block\n",
        "        - Causal Self-Attention and SwiGLU as main elements\n",
        "        - Pre-normalization via RMSNorm\n",
        "        - Regularization with dropouts before residuals\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.ln_1 = RMSNorm(config.hidden_dim)\n",
        "        self.res_dropout_1 = nn.Dropout(config.dropout)\n",
        "        self.attn = MHLASelfAttention(config)\n",
        "\n",
        "        self.ln_2 = RMSNorm(config.hidden_dim)\n",
        "        self.res_dropout_2 = nn.Dropout(config.dropout)\n",
        "        self.mlp = SwiGLU(config)\n",
        "\n",
        "    def forward(self, x: Tensor, attention_mask: Tensor = None) -> Tensor:\n",
        "        \"\"\"Apply Transformer Block to input data.\n",
        "\n",
        "        Args:\n",
        "            x: input tensor, shape [bs, seq len, hidden dim]\n",
        "            attention_mask: mask with zeros for pad tokens, shape [bs, seq len, hidden dim]\n",
        "        Returns:\n",
        "            result tensor, shape [bs, seq len, hidden dim]\n",
        "        \"\"\"\n",
        "        x_attn = self.attn(self.ln_1(x), attention_mask)\n",
        "        x = x + self.res_dropout_1(x_attn)\n",
        "\n",
        "        x_ff = self.mlp(self.ln_2(x))\n",
        "        x = x + self.res_dropout_2(x_ff)\n",
        "        return x\n",
        "    \n",
        "\n",
        "class ModifiedTransformerForCausalLM(nn.Module, PyTorchModelHubMixin):\n",
        "    def __init__(self, config: TransformerConfig):\n",
        "        \"\"\"Transformer model for Language Modeling\"\"\"\n",
        "        super().__init__()\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.max_seq_len = config.max_seq_len\n",
        "        self.n_layer = config.n_layer\n",
        "        self.n_head = config.n_head\n",
        "        self.hidden_dim = config.hidden_dim\n",
        "        self.dropout = config.dropout\n",
        "\n",
        "        self.token_emb = nn.Embedding(self.vocab_size, self.hidden_dim)\n",
        "        self.emb_dropout = nn.Dropout(config.dropout)\n",
        "        self.layers = nn.ModuleList([ModifiedBlock(config) for _ in range(config.n_layer)])\n",
        "        self.ln_final = RMSNorm(config.hidden_dim)\n",
        "        self.lm_head = nn.Linear(self.hidden_dim, self.vocab_size, bias=False)\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "        n_params = sum(p.numel() for p in self.parameters())\n",
        "        print(f\"Number of parameters: {n_params / 1e6:.2f}M\")\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "        elif isinstance(module, RMSNorm):\n",
        "            torch.nn.init.ones_(module.scale)\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor = None) -> Tensor:\n",
        "        \"\"\"Calculate logits for given input ids.\n",
        "\n",
        "        Args:\n",
        "            x: input tensor, shape [bs, seq len, hidden dim]\n",
        "            attention_mask: mask with zeros for pad tokens, shape [bs, seq len, hidden dim]\n",
        "        Returns:\n",
        "            logits, shape [bs, seq len, hidden dim]\n",
        "        \"\"\"\n",
        "        x = self.token_emb(input_ids)\n",
        "        x = self.emb_dropout(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, attention_mask)\n",
        "        x = self.ln_final(x)\n",
        "        logits = self.lm_head(x)\n",
        "        return logits\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def generate(\n",
        "        self, idx: Tensor, max_new_tokens, eos_token_id, temperature=1.0, do_sample=False, top_k=None\n",
        "    ) -> Tensor:\n",
        "        \"\"\"Take a conditioning sequence of indices and complete the sequence max_new_tokens times,\n",
        "        feeding the predictions back into the model each time.\n",
        "\n",
        "        Args:\n",
        "            idx: tensor with conditional tokens, shape [seq len]\n",
        "            max_new_tokens: maximum number of new tokens\n",
        "            eos_token_id: index of EOS token to stop generation\n",
        "            temperature, do_sample, top_k: generation parameters\n",
        "        Return:\n",
        "            tensor with generated indexes\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx if idx.shape[1] <= self.max_seq_len else idx[:, -self.max_seq_len :]\n",
        "            logits = self(idx_cond)\n",
        "\n",
        "            # 1. Pluck the logits at the final step and scale by desired temperature\n",
        "            logits = logits[:, -1, :]  # [bs, vocab_size]\n",
        "            logits = logits / temperature\n",
        "\n",
        "            # 2. Optionally crop the logits to only the top k options\n",
        "            if top_k is not None:\n",
        "                kth_value = torch.topk(logits, top_k, dim=-1)[0][..., -1, None]\n",
        "                mask = logits < kth_value\n",
        "                logits[mask] = float(\"-inf\")\n",
        "\n",
        "            # 3. apply softmax to convert logits to probabilities\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "            # 4. Either sample from the distribution or take the most likely element\n",
        "            if do_sample:\n",
        "                idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            else:\n",
        "                idx_next = torch.argmax(probs, dim=-1, keepdim=True)\n",
        "\n",
        "            # 5. Append sampled index to the running sequence and continue\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "            if idx_next == eos_token_id:\n",
        "                break\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhdavMmSDujw"
      },
      "source": [
        "# Train Loop [2 + 2 Ğ±Ğ°Ğ»Ğ»Ğ°]\n",
        "\n",
        "ĞĞ°ÑÑ‚Ğ°Ğ»Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ.\n",
        "ĞĞµĞ±Ğ¾Ğ»ÑŒÑˆÑƒÑ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡Ğ°Ñ‚ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾, Ğ½Ğ¾ Ğ»ÑƒÑ‡ÑˆĞµ Ğ²ÑĞµĞ³Ğ¾ Ğ²Ğ¾ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ GPU, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ½Ğ° Google Colab.\n",
        "\n",
        "Ğ—Ğ° Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ 2 Ğ±Ğ°Ğ»Ğ»Ğ°, Ğ¸ ĞµÑ‰Ğµ 2 Ğ±Ğ°Ğ»Ğ»Ğ° - ĞµÑĞ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ°ÑƒÑ‡Ğ¸Ğ»Ğ°ÑÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ‚ÑŒ Ğ°Ğ½ĞµĞºĞ´Ğ¾Ñ‚Ñ‹.\n",
        "\n",
        "ĞĞµ Ğ·Ğ°Ğ±ÑƒĞ´ÑŒÑ‚Ğµ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€Ğ¸Ñ‚ÑŒ, Ñ‡Ñ‚Ğ¾ Ğ²Ñ‹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ğ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğµ Ğ²ĞµÑĞ° Ğ½Ğ° HF Ğ¸ Ñƒ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑÑ‰ĞµĞ³Ğ¾ ÑĞºĞ°Ñ‡Ğ°ĞµÑ‚ÑÑ Ğ½ÑƒĞ¶Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wtAiR_aDxed",
        "outputId": "1e5ecf77-0a8c-4b79-be67-1fe9f54cc4ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch #0\n",
            "tensor([[ 817,  411,  345,   33, 1023, 1023, 1023, 1023, 1023],\n",
            "        [ 594,  368,  851,  321,  325,  641,  322,   63, 1023]])\n",
            "\n",
            "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "Batch #1\n",
            "tensor([[ 560,  358,  362,  709,  891,  327,  387,  340,  387,  595,  757,  662,\n",
            "          945, 1023]])\n",
            "\n",
            "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ Ğ¸ ĞºĞ°Ğº Ğ·Ğ°Ğ²Ğ¾Ñ€Ğ°Ñ‡Ğ¸Ğ²Ğ°Ñ‚ÑŒ ÑĞµĞ¼Ğ¿Ğ»Ñ‹ Ğ² Ğ±Ğ°Ñ‚Ñ‡\n",
        "# Ğ Ğ°Ğ·Ğ½Ñ‹Ğµ Ñ‚ĞµĞºÑÑ‚Ñ‹ Ğ¸Ğ¼ĞµÑÑ‚ Ñ€Ğ°Ğ·Ğ½ÑƒÑ Ğ´Ğ»Ğ¸Ğ½Ñƒ, Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ±ÑƒĞ´ĞµÑ‚ Ğ¿Ğ°Ğ´Ğ¸Ñ‚ÑŒ Ğ´Ğ¾ ÑĞ°Ğ¼Ğ¾Ğ³Ğ¾ Ğ´Ğ»Ğ¸Ğ½Ğ° ÑĞµĞ¼Ğ¿Ğ»Ğ°\n",
        "# Ğ¢Ğ°Ğº Ğ¶Ğµ Ğ·Ğ°Ğ²ĞµĞ´ĞµĞ¼ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½ÑƒÑ Ğ¼Ğ°ÑĞºÑƒ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ¼ĞµÑ…Ğ°Ğ½Ğ¸Ğ·Ğ¼ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ½Ğµ ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ğ» Ğ¿Ğ°Ğ´Ğ¸Ğ½Ğ³Ğ¸\n",
        "\n",
        "\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, tokenizer):\n",
        "        self.texts = texts\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        texts = self.texts[idx]\n",
        "        tokenized_sequence = self.tokenizer.encode(texts)\n",
        "        return tokenized_sequence\n",
        "\n",
        "\n",
        "def data_collator(\n",
        "    tokenized_sequences: list[list[int]], pad_token_id: int, max_seq_len: int = None\n",
        ") -> tuple[torch.Tensor, torch.Tensor]:\n",
        "    batch_size = len(tokenized_sequences)\n",
        "    max_batch_seq_len = min(max_seq_len, max((len(it) for it in tokenized_sequences)))\n",
        "\n",
        "    input_ids = torch.full((batch_size, max_batch_seq_len), pad_token_id)\n",
        "    attention_mask = torch.zeros((batch_size, max_batch_seq_len))\n",
        "\n",
        "    for i, tok_seq in enumerate(tokenized_sequences):\n",
        "        cur_len = min(len(tok_seq), max_batch_seq_len)\n",
        "        input_ids[i, :cur_len] = torch.tensor(tok_seq[:cur_len])\n",
        "        attention_mask[i, :cur_len] = 1\n",
        "\n",
        "    return input_ids, attention_mask\n",
        "\n",
        "\n",
        "def create_dataloader(dataset, pad_token_id, max_seq_len, batch_size, is_train):\n",
        "    collate_fn = partial(data_collator, pad_token_id=pad_token_id, max_seq_len=max_seq_len)\n",
        "    return DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=is_train, drop_last=is_train, collate_fn=collate_fn, pin_memory=True\n",
        "    )\n",
        "\n",
        "\n",
        "_d = TextDataset([\"ĞŸÑ€Ğ¸Ğ²ĞµÑ‚!\", \"ĞšĞ°Ğº Ñ‚Ğ²Ğ¾Ğ¸ Ğ´ĞµĞ»Ğ°?\", \"ĞÑÑ‚Ğ°Ğ»Ğ¾ÑÑŒ ÑĞ¾Ğ²ÑĞµĞ¼ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¾ ĞºĞ¾Ğ½Ñ†Ğ°\"], tokenizer)\n",
        "_dl = create_dataloader(_d, tokenizer.eos_token_id, max_seq_len=16, batch_size=2, is_train=False)\n",
        "\n",
        "for i, batch in enumerate(_dl):\n",
        "    print(f\"Batch #{i}\")\n",
        "    input_ids, attn_mask = batch\n",
        "    print(input_ids, attn_mask, sep=\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "i719AOdQK993"
      },
      "outputs": [],
      "source": [
        "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps):\n",
        "    \"\"\"Scheduler for Optimizer with linear warmup and linear decay to the end of training\n",
        "\n",
        "    Args:\n",
        "        optimizer: torch optimizer to control learning rate\n",
        "        num_warmup_steps: number of warmup steps\n",
        "        num_training_steps: total number of training steps\n",
        "    Return:\n",
        "        torch learning rate scheduler\n",
        "    \"\"\"\n",
        "    assert num_training_steps >= num_warmup_steps\n",
        "\n",
        "    def lr_lambda(current_step):\n",
        "        if current_step < num_warmup_steps:\n",
        "            return float(current_step) / float(max(1, num_warmup_steps))\n",
        "        else:\n",
        "            return max(0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps)))\n",
        "    return torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "\n",
        "\n",
        "def cross_entropy_loss(input_ids: Tensor, attention_mask: Tensor, logits: Tensor) -> Tensor:\n",
        "    \"\"\"Calculate Cross-Entropy loss for Language Modeling task\n",
        "    Under the hood:\n",
        "    1. Create targtes based on input ids\n",
        "    2. Masked out tokens corresponded to paddings\n",
        "    3. Calculate cross entropy loss\n",
        "\n",
        "    Args:\n",
        "        input_ids: tensor with input ids, shape [bs, seq len]\n",
        "        attention_mask: mask with zeros for pad tokens, shape [bs, seq len]\n",
        "        logits: predicted logits, shape [bs, seq len, vocab size]\n",
        "    Return:\n",
        "        cross entropy loss, single-item tensor\n",
        "    \"\"\"\n",
        "    # Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ»Ğ¾Ğ³Ğ¸Ñ‚Ñ‹ ÑĞ¾ ÑĞ´Ğ²Ğ¸Ğ³Ğ¾Ğ¼ Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ñ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ°\n",
        "    logits = logits[:, :-1, :]\n",
        "    targets = input_ids[:, 1:]\n",
        "    target_mask = attention_mask[:, 1:]\n",
        "\n",
        "    targets = targets.clone()\n",
        "    targets[target_mask == 0] = -100\n",
        "\n",
        "    logits_flat = logits.reshape(-1, logits.size(-1))\n",
        "    targets_flat = targets.reshape(-1)\n",
        "    \n",
        "    loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat, ignore_index=-100)\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "SPYdF52zXtoX"
      },
      "outputs": [],
      "source": [
        "# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ğ¼ Ñ‚Ñ€ĞµĞ½ĞµÑ€Ğ° Ñ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğ¼Ğ¸ Ğ³Ğ¸Ğ¿ĞµÑ€Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ\n",
        "\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        learning_rate=3e-4,\n",
        "        weight_decay=0.01,\n",
        "        clip_grad_norm=1.0,\n",
        "        n_steps=8_000,\n",
        "        val_every_n_steps=1_000,\n",
        "        plot_every_n_steps=100,\n",
        "    ):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.weight_decay = weight_decay\n",
        "        self.clip_grad_norm = clip_grad_norm\n",
        "        self.n_steps = n_steps\n",
        "        self.val_every_n_steps = val_every_n_steps\n",
        "        self.plot_every_n_steps = plot_every_n_steps\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = \"cuda\"\n",
        "        elif torch.backends.mps.is_available():\n",
        "            self.device = \"mps\"\n",
        "        else:\n",
        "            self.device = \"cpu\"\n",
        "        print(\"running on device\", self.device)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, model, val_loader):\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
        "            input_ids, attention_mask = batch\n",
        "            input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "            attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)  # [bs; seq len; vocab size]\n",
        "            val_loss += cross_entropy_loss(input_ids, attention_mask, logits)\n",
        "        return val_loss / len(val_loader)\n",
        "\n",
        "    def run(self, model, train_loader, val_loader):\n",
        "        model = model.to(self.device)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer, num_warmup_steps=0.1 * self.n_steps, num_training_steps=self.n_steps\n",
        "        )\n",
        "        model.train()\n",
        "\n",
        "        plotlosses = PlotLosses(figsize=(15, 9), step_names=\"Step\")\n",
        "        logs = {\"lr\": 0, \"epoch\": 0}\n",
        "\n",
        "        data_iter = iter(train_loader)\n",
        "        for iter_num in range(self.n_steps):\n",
        "            try:\n",
        "                batch = next(data_iter)\n",
        "            except StopIteration:\n",
        "                data_iter = iter(train_loader)\n",
        "                logs[\"epoch\"] += 1\n",
        "                batch = next(data_iter)\n",
        "\n",
        "            input_ids, attention_mask = batch\n",
        "            input_ids = input_ids.to(self.device, non_blocking=True)\n",
        "            attention_mask = attention_mask.to(self.device, non_blocking=True)\n",
        "\n",
        "            logits = model(input_ids, attention_mask)  # [bs; seq len; vocab size]\n",
        "            loss = cross_entropy_loss(input_ids, attention_mask, logits)\n",
        "\n",
        "            # backprop and update the parameters\n",
        "            model.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), self.clip_grad_norm)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            if iter_num > 0 and iter_num % self.val_every_n_steps == 0:\n",
        "                val_loss = self.validate(model, val_loader)\n",
        "                plotlosses.update({\"val_loss\": val_loss.item()}, current_step=iter_num)\n",
        "                plotlosses.send()\n",
        "                model.train()\n",
        "\n",
        "            if iter_num % self.plot_every_n_steps == 0:\n",
        "                logs[\"loss\"] = loss.item()\n",
        "                logs[\"lr\"] = scheduler.get_last_lr()[0]\n",
        "                plotlosses.update(logs, current_step=iter_num)\n",
        "                plotlosses.send()\n",
        "\n",
        "        val_loss = self.validate(model, val_loader)\n",
        "        plotlosses.update({\"val_loss\": val_loss.item()}, current_step=iter_num)\n",
        "        plotlosses.send()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "yK1BpJflMTAi"
      },
      "outputs": [],
      "source": [
        "# Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ‚Ñ€ĞµĞ½Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ñ‚Ğ°Ğ»Ğ¾Ğ°Ğ´ĞµÑ€Ñ‹\n",
        "\n",
        "\n",
        "MAX_SEQ_LEN = 128\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "train_dataset = TextDataset(dataset[\"train\"][\"text\"], tokenizer)\n",
        "train_dataloader = create_dataloader(\n",
        "    train_dataset, tokenizer.eos_token_id, max_seq_len=MAX_SEQ_LEN, batch_size=BATCH_SIZE, is_train=True\n",
        ")\n",
        "\n",
        "test_dataset = TextDataset(dataset[\"test\"][\"text\"], tokenizer)\n",
        "test_dataloader = create_dataloader(\n",
        "    test_dataset, tokenizer.eos_token_id, max_seq_len=MAX_SEQ_LEN, batch_size=BATCH_SIZE, is_train=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53jHSgMZECGl",
        "outputId": "8eb387fb-d203-4270-eaa3-938df6c67b90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters: 10.55M\n"
          ]
        }
      ],
      "source": [
        "# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ\n",
        "\n",
        "config = model_configs[\"mini\"]\n",
        "model = TransformerForCausalLM(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ğ¯ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ°Ğ»ÑÑ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ, Ğ»Ğ¾ÑÑ Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ \"Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ\", Ğ½Ğ¾ Ñ ÑƒÑĞ¿ĞµĞ» Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ‚Ğ°ĞºĞ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ nano Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ğ¸ Ñ‚Ğ¾ Ğ½Ğµ ÑĞ¼Ğ¾Ğ³ ĞµÑ‘ Ğ·Ğ°Ğ»Ğ¸Ñ‚ÑŒ Ğ² Ñ€ĞµĞ¿Ñƒ (ÑĞ¼Ğ¾Ğ³, Ğ½Ğ¾ Ğ¾Ğ½Ğ° Ğ·Ğ°Ñ‚ĞµÑ€Ğ»Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğ½ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, Ñ‚Ğ°Ğº Ñ‡Ñ‚Ğ¾ Ñ Ñ€ĞµÑˆĞ¸Ğ» Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ \"ÑƒĞ¼Ğ½ÑƒÑ\" Ğ±ĞµĞ¹Ğ·Ğ»Ğ°Ğ¹Ğ½Ğ¾Ğ²ÑƒÑ, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞ»Ğ°ÑÑŒ Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ĞµĞ¹ Ğ»ÑƒÑˆÑ‡Ğµ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ RoPE Ğ¸ MHLA\n",
        "\n",
        "#config = model_configs[\"nano\"]\n",
        "#model = ModifiedTransformerForCausalLM(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMUsjHl4Nkoa",
        "outputId": "705ff33c-a038-438c-f2a9-e6e65bd504ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running on device cuda\n"
          ]
        }
      ],
      "source": [
        "# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‚Ñ€ĞµĞ½ĞµÑ€Ğ°\n",
        "\n",
        "trainer = Trainer(learning_rate=3e-4) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "1nUgUfpKK993",
        "outputId": "845701be-08b3-4835-c407-e2a7195c35e7"
      },
      "outputs": [],
      "source": [
        "# ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ goes brrrr!\n",
        "\n",
        "trainer.run(model, train_dataloader, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[208, 168, 324, 486, 425, 391, 377, 548, 370, 687, 383]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Ğ¨Ñ‚Ğ¸Ñ€Ğ»Ğ¸Ñ† Ğ¿Ñ€Ğ¸ÑˆĞµĞ» Ğ´Ğ¾Ğ¼Ğ¾Ğ¹, Ğ° Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼ ĞºĞ°Ñ€Ğ°. '"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"Ğ¨Ñ‚Ğ¸Ñ€Ğ»Ğ¸Ñ† Ğ¿Ñ€Ğ¸ÑˆĞµĞ» Ğ´Ğ¾Ğ¼Ğ¾Ğ¹\"\n",
        "input_ids = torch.tensor(tokenizer.encode(text)[:-1], device=trainer.device)[None, :]\n",
        "print(input_ids)\n",
        "model_output = model.generate(\n",
        "    input_ids, max_new_tokens=200, eos_token_id=tokenizer.eos_token_id, temperature=1.6, do_sample=True, top_k=10\n",
        ")\n",
        "tokenizer.decode(model_output[0].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "YFi7M9ExHWv9",
        "outputId": "5d4d7528-7475-4f28-8543-c35607c03430"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.3M/42.3M [00:47<00:00, 889kB/s] \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/NotHotTryHard/llm-course-hw1/commit/9b5e92319f4c9164c42863e2e51d9a732e92ec7c', commit_message='Push model using huggingface_hub.', commit_description='', oid='9b5e92319f4c9164c42863e2e51d9a732e92ec7c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/NotHotTryHard/llm-course-hw1', endpoint='https://huggingface.co', repo_type='model', repo_id='NotHotTryHard/llm-course-hw1'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ° Ñ…Ğ°Ğ±\n",
        "\n",
        "model.push_to_hub(REPO_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WrMwV9zK993"
      },
      "source": [
        "ĞŸĞ¾Ğ¸Ğ³Ñ€Ğ°Ğ¹Ñ‚ĞµÑÑŒ Ñ Ğ³Ğ¸Ğ¿ĞµÑ€Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸, Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ¾Ğ±ÑƒÑ‡Ğ¸Ñ‚ÑŒ `mini` Ğ¸ `small` Ğ²ĞµÑ€ÑĞ¸Ğ¸.\n",
        "ĞŸĞ¾ÑÑ‚Ğ°Ñ€Ğ°Ğ¹Ñ‚ĞµÑÑŒ Ğ´Ğ¾Ğ±Ğ¸Ñ‚ÑŒÑÑ ĞºĞ°Ğº Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ±Ğ¾Ğ»ĞµĞµ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° ĞºĞ°Ğº Ğ² Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ°Ñ… Ğ»Ğ¾ÑÑĞ°, Ñ‚Ğ°Ğº Ğ¸ Ğ¿Ñ€Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ¾Ñ†ĞµĞ½ĞºĞµ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸.\n",
        "\n",
        "### Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ°Ğ»Ğ»Ñ‹\n",
        "\n",
        "Ğ’Ñ‹ Ñ‚Ğ°ĞºĞ¶Ğµ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ±Ğ°Ğ»Ğ»Ñ‹:\n",
        "- Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Rotary Positional Embedding **[4 Ğ±Ğ°Ğ»Ğ»Ğ°]**\n",
        "- Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Multi-Head Latent Attention **[2 Ğ±Ğ°Ğ»Ğ»]**\n",
        "- ĞÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ½Ğ° ğŸ¤—: ĞºĞ°Ñ€Ñ‚Ğ¾Ñ‡ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ, Ñ€ĞµĞ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ğ¼Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ **[2 Ğ±Ğ°Ğ»Ğ»]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so8bIDy5dKXM"
      },
      "source": [
        "# Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ´ĞµĞ» Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑÑ‰ĞµĞ³Ğ¾"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0ZplshN5HtRb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Fetching 7 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 43561.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of parameters: 0.50M\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer.from_pretrained(REPO_NAME)\n",
        "check_model = TransformerForCausalLM.from_pretrained(REPO_NAME)\n",
        "check_model = check_model.to(device)\n",
        "check_model = check_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "araF_3noK994"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Ğ¨Ñ‚Ğ¸Ñ€Ğ»Ğ¸Ñ† Ğ¿Ñ€Ğ¸ÑˆĞµĞ» Ğ´Ğ¾Ğ¼Ğ¾Ğ¹Ğ²Ñ€Ğ°Ñ‰Ğ¸Ğ¹ Ñ Ğ½Ğ°Ğ·Ğ°Ğ´ÑŒ.   Ğ’Ğ°ÑĞ½Ğ¾ Ğ² ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ² ĞºĞ¾Ğ³Ğ¾. Ğ”Ğ°Ğ²Ñ‚Ğ¸Ñ€Ğ»Ğ¸Ñ†: - Ğ¯ Ğ² ĞºĞ»ÑŒÑˆĞµ! '"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"Ğ¨Ñ‚Ğ¸Ñ€Ğ»Ğ¸Ñ† Ğ¿Ñ€Ğ¸ÑˆĞµĞ» Ğ´Ğ¾Ğ¼Ğ¾Ğ¹\"\n",
        "input_ids = torch.tensor(tokenizer.encode(text), device=device)\n",
        "\n",
        "model_output = check_model.generate(\n",
        "    input_ids[None, :], max_new_tokens=200, eos_token_id=tokenizer.eos_token_id, temperature=2.0, do_sample=True, top_k=10\n",
        ")\n",
        "tokenizer.decode(model_output[0].tolist())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp2_env",
      "language": "python",
      "name": "nlp2_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "013f1b28161c4b2888981b2279309a08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07238cfa6bd34bf0917a8622a1cd3b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e3f8d3e5e5b4492a59f0d7d3186877e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1208ee3c939b4e18bcbf992a00bde69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_513fd997a1444193bcaa161bb7c4e6b7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_963ec243a52f481d8e67977600e9b34d",
            "value": "â€‡135497/135497â€‡[00:09&lt;00:00,â€‡15155.09it/s]"
          }
        },
        "17262cca283248a98297387d6824d5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed5bfb7134314419a909b305e43d432b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f0ae019189404e27a4286b05922c8f9e",
            "value": "Loadingâ€‡data:â€‡100%"
          }
        },
        "1a8fccc151714a19856de84a0416d3d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e923b43f03f4bfe8c1315d8e98e049b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f3b2354ef974753bf0057ff07cdd208": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23829bfc269042948448534c24709134": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afb8e5c8b9ef4336bf6e2eee88d4e114",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ecd900fa3e114439822257ba77381f0a",
            "value": "README.md:â€‡100%"
          }
        },
        "24a0f86cb4504f6a88c4bcc9410a6882": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25279ff26e0046899b173f33e3cea185": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27d8bbba523844ce9568c9d8b6690cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4cf7e2c4a664fa398e6e60ae11e2348",
              "IPY_MODEL_808c00da14224708918d15a5000434fc",
              "IPY_MODEL_da58846238f54b6790acd3898da7b9a6"
            ],
            "layout": "IPY_MODEL_880b38716d5f4eb5b4f7dfba3390dc45"
          }
        },
        "34bf217aa66f4fb29d09f35f592c1bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e38bd08f29d40559bc7d339e03bd4c2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8f3dde7227494dd9b0774ce28b388274",
            "value": "dataset.csv:â€‡100%"
          }
        },
        "408079bc18cf4307b7a4aa0a81591979": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "466b7df8811a413c95f08a580de6b89a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "468d88309904488a817e7b81a392c8b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "494d0853e39641daa0805645ce6beb17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34bf217aa66f4fb29d09f35f592c1bc9",
              "IPY_MODEL_d49f51a25b964249852b50a2acc49634",
              "IPY_MODEL_d6730505ea7d431fbfd80aa7a01dc790"
            ],
            "layout": "IPY_MODEL_73a9344dc79e43f091c8d1b223cbcee4"
          }
        },
        "4b35e808896a4a37aab51a068f242c43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bc0fba67ddf478991c47aa6cab98ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6c63b0273ea460eb5e153e48101e332",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07238cfa6bd34bf0917a8622a1cd3b0d",
            "value": 1
          }
        },
        "4bcfbe536a2d47a39d4293d998636243": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c1ebcad0d764e60a4948434d9993a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e38bd08f29d40559bc7d339e03bd4c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "513fd997a1444193bcaa161bb7c4e6b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51b3b59a23ad411988fc656d30d8fc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a8fccc151714a19856de84a0416d3d8",
            "max": 135497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e923b43f03f4bfe8c1315d8e98e049b",
            "value": 135497
          }
        },
        "51fa888c7bf34a74a0742fc197d9487a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "564c90bbde8442f59aa264ace4f8a90b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "566df9d46f7943b7b672fe7dd9f7417c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d1434a6307d4ba9bed46f5d4ae730c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_408079bc18cf4307b7a4aa0a81591979",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c541c5f56dd2474b84182f9703b4cda7",
            "value": "â€‡150553/0â€‡[00:02&lt;00:00,â€‡85464.42â€‡examples/s]"
          }
        },
        "69fa3278c9ff402784c86c44d74e3e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cb7655e3cd541e5855462433aa534be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7007abc4f18e4d7997aa1d7265c25eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73a9344dc79e43f091c8d1b223cbcee4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a8ce73ceb64b688147bb7a71d4c2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75dbd3da373541b2bc952f7f6a164624": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75ddc70c138c42389c14a293a68aade2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "808c00da14224708918d15a5000434fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86d07832c915484fa50db62c333922ec",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51fa888c7bf34a74a0742fc197d9487a",
            "value": 1024
          }
        },
        "8142e932c2b94414bd27d4223c3a3d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82a2000df7e543029f0964f399642d5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cb7655e3cd541e5855462433aa534be",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_74a8ce73ceb64b688147bb7a71d4c2c9",
            "value": "â€‡99.0/99.0â€‡[00:00&lt;00:00,â€‡6.21kB/s]"
          }
        },
        "86d07832c915484fa50db62c333922ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "880b38716d5f4eb5b4f7dfba3390dc45": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f3dde7227494dd9b0774ce28b388274": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91e13de6ce154bb09173c4f9f333611b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f01f1d458a453d8241de282a374b19",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b26a32b517324844b77e3de793b6c47d",
            "value": "Fetchingâ€‡3â€‡files:â€‡100%"
          }
        },
        "946f2a1b3aa34be2a278e291fdb530e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "963ec243a52f481d8e67977600e9b34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9970c0d3b42b4ff08d31eeae1d0efe51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fdad1a5749346b09daf54d983a22964": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a09b3fed74ed42efb5a3f71e5eae676c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_17262cca283248a98297387d6824d5bb",
              "IPY_MODEL_51b3b59a23ad411988fc656d30d8fc8a",
              "IPY_MODEL_1208ee3c939b4e18bcbf992a00bde69c"
            ],
            "layout": "IPY_MODEL_4c1ebcad0d764e60a4948434d9993a2f"
          }
        },
        "a4f01f1d458a453d8241de282a374b19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7cfb7fe4e0e484784c16947848f296e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23829bfc269042948448534c24709134",
              "IPY_MODEL_c59603b6d2484a95b18f009a81d5bc66",
              "IPY_MODEL_82a2000df7e543029f0964f399642d5d"
            ],
            "layout": "IPY_MODEL_f4de1a432cd54914939b6b70e6af7dcc"
          }
        },
        "afb8e5c8b9ef4336bf6e2eee88d4e114": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b08ba319d12f4d15bd7ec8bea32a90f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b26a32b517324844b77e3de793b6c47d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4cf7e2c4a664fa398e6e60ae11e2348": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fdad1a5749346b09daf54d983a22964",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9970c0d3b42b4ff08d31eeae1d0efe51",
            "value": "Buildingâ€‡vocabulary:â€‡100%"
          }
        },
        "b976e96a647b4f40a50965b3cef1c8a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b9619cfb0f4451985c6466b0486fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd8e490fbdc5420f97d4c94f5e61b5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25279ff26e0046899b173f33e3cea185",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_24a0f86cb4504f6a88c4bcc9410a6882",
            "value": "Generatingâ€‡trainâ€‡split:â€‡"
          }
        },
        "be6ceb6f27af40aba535c445806e297b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ddc70c138c42389c14a293a68aade2",
            "max": 15056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_946f2a1b3aa34be2a278e291fdb530e8",
            "value": 15056
          }
        },
        "c541c5f56dd2474b84182f9703b4cda7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c59603b6d2484a95b18f009a81d5bc66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6975b8856484e2f96d78fe4a23a8e10",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bcfbe536a2d47a39d4293d998636243",
            "value": 99
          }
        },
        "ce6945736f7c4c839190e0404f370a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91e13de6ce154bb09173c4f9f333611b",
              "IPY_MODEL_f81001a64a784ae7a8d09fe258376e1d",
              "IPY_MODEL_ffa04c096fc0464db8182467a307a2ae"
            ],
            "layout": "IPY_MODEL_b976e96a647b4f40a50965b3cef1c8a5"
          }
        },
        "d49f51a25b964249852b50a2acc49634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e3f8d3e5e5b4492a59f0d7d3186877e",
            "max": 42450463,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_566df9d46f7943b7b672fe7dd9f7417c",
            "value": 42450463
          }
        },
        "d6730505ea7d431fbfd80aa7a01dc790": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_466b7df8811a413c95f08a580de6b89a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_75dbd3da373541b2bc952f7f6a164624",
            "value": "â€‡42.5M/42.5Mâ€‡[00:00&lt;00:00,â€‡156MB/s]"
          }
        },
        "d6c63b0273ea460eb5e153e48101e332": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "da58846238f54b6790acd3898da7b9a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7007abc4f18e4d7997aa1d7265c25eb4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8142e932c2b94414bd27d4223c3a3d6c",
            "value": "â€‡1024/1024â€‡[17:39&lt;00:00,â€‡â€‡1.35s/it]"
          }
        },
        "e4231b41f41d421facafcdefb89969d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd8e490fbdc5420f97d4c94f5e61b5c5",
              "IPY_MODEL_4bc0fba67ddf478991c47aa6cab98ff4",
              "IPY_MODEL_5d1434a6307d4ba9bed46f5d4ae730c0"
            ],
            "layout": "IPY_MODEL_f470bf33537d462a883ef2d57df8bfbc"
          }
        },
        "e5087d27c4f14a28bfb73740fa147d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef5bee8e8d2f4d8c91ba14e77dda8d01",
              "IPY_MODEL_be6ceb6f27af40aba535c445806e297b",
              "IPY_MODEL_f2a0e82016804d2ca04aeb19c0d936e5"
            ],
            "layout": "IPY_MODEL_564c90bbde8442f59aa264ace4f8a90b"
          }
        },
        "e6975b8856484e2f96d78fe4a23a8e10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd900fa3e114439822257ba77381f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed5bfb7134314419a909b305e43d432b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef5bee8e8d2f4d8c91ba14e77dda8d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f3b2354ef974753bf0057ff07cdd208",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_468d88309904488a817e7b81a392c8b3",
            "value": "100%"
          }
        },
        "f0ae019189404e27a4286b05922c8f9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2a0e82016804d2ca04aeb19c0d936e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f94a9f0d86294b0288ad87412ec2ca5d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_69fa3278c9ff402784c86c44d74e3e70",
            "value": "â€‡15056/15056â€‡[00:14&lt;00:00,â€‡853.37it/s]"
          }
        },
        "f470bf33537d462a883ef2d57df8bfbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4de1a432cd54914939b6b70e6af7dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f81001a64a784ae7a8d09fe258376e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_013f1b28161c4b2888981b2279309a08",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9b9619cfb0f4451985c6466b0486fb9",
            "value": 3
          }
        },
        "f94a9f0d86294b0288ad87412ec2ca5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa04c096fc0464db8182467a307a2ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b35e808896a4a37aab51a068f242c43",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b08ba319d12f4d15bd7ec8bea32a90f4",
            "value": "â€‡3/3â€‡[00:00&lt;00:00,â€‡202.59it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
